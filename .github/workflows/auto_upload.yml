name: Upload GSEs in a date range

on:
  workflow_dispatch:
    inputs:
      start:
        description: 'start data e.g. [2020/02/24]'
        required: true
      end:
        description: 'end data e.g. [2020/04/27]'
        required: true


jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        python-version: [ "3.12" ]
        os: [ ubuntu-latest ]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install uv
          uv pip install torch==2.3.1+cpu -f https://download.pytorch.org/whl/torch_stable.html --system
          uv pip install git+https://github.com/databio/bedboss.git@dev#egg=bedboss --system

      - name: Do something here
        run: |
            echo "Hello, ${{ github.actor }}"
            echo "The GSE is ${{ inputs.gse }}"

      - name: Upload Project
        run: bedboss geo upload-all --outfolder /tmp/out --start-date ${{ inputs.start }} --end-date ${{ inputs.end }}  --no-use-skipper --lite --bedbase-config config.yaml --no-use-skipper --no-preload --search-limit 1
        # TODO: delete --search-limit 1 - this is just for testing
        env:
          POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          QDRANT_HOST: ${{ secrets.QDRANT_HOST }}
          QDRANT_API_KEY: ${{ secrets.QDRANT_API_KEY }}
          AWS_ENDPOINT_URL: ${{ secrets.AWS_ENDPOINT_URL }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
